{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdp/88wgd8k8iZTs6irdWy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachid-boudour/SASRec-model/blob/master/SASrec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Q_jZXMoqHGOa",
        "outputId": "81618551-2a0b-4e4f-f59b-0b08663f0913"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "CSV not found at D:/Doctorat/Recommandation_paper/RecCode/Datasets/interactions200K_collab_V2.csv. Put the file there or update the path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3216625005.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"D:/Doctorat/Recommandation_paper/RecCode/Datasets/interactions200K_collab_V2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CSV not found at {p}. Put the file there or update the path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: CSV not found at D:/Doctorat/Recommandation_paper/RecCode/Datasets/interactions200K_collab_V2.csv. Put the file there or update the path."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. üîπ Chargement du dataset\n",
        "p = Path(\"D:/Doctorat/Recommandation_paper/RecCode/Datasets/interactions200K_collab_V2.csv\")\n",
        "if not p.exists():\n",
        "    raise FileNotFoundError(f\"CSV not found at {p}. Put the file there or update the path.\")\n",
        "df = pd.read_csv(p)\n",
        "\n",
        "# 2. üîπ Tri par utilisateur et par timestep\n",
        "df = df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
        "\n",
        "# 3. üîπ Encodage des items\n",
        "item_encoder = LabelEncoder()\n",
        "df[\"service_id_enc\"] = item_encoder.fit_transform(df[\"service_id\"])\n",
        "\n",
        "# Mapping inverse si besoin\n",
        "idx2item = dict(enumerate(item_encoder.classes_))\n",
        "\n",
        "# 4. üîπ Construction des s√©quences par utilisateur\n",
        "def make_sequences(df, min_len=2):\n",
        "    sequences = []\n",
        "    grouped = df.groupby(\"user_id\")[\"service_id_enc\"].apply(list)\n",
        "    for items in grouped:\n",
        "        if len(items) >= min_len:\n",
        "            for i in range(1, len(items)):\n",
        "                seq = items[:i]\n",
        "                target = items[i]\n",
        "                sequences.append((seq, target))\n",
        "    return sequences\n",
        "\n",
        "sequences = make_sequences(df)\n",
        "\n",
        "# 5. üîπ Dataset PyTorch\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, sequences, max_len, item_count):\n",
        "        self.sequences = sequences\n",
        "        self.max_len = max_len\n",
        "        self.item_count = item_count\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "        padded_seq = [0] * (self.max_len - len(seq)) + seq[-self.max_len:]\n",
        "        return torch.tensor(padded_seq), torch.tensor(target)\n",
        "\n",
        "max_seq_len = 10\n",
        "item_count = len(item_encoder.classes_)\n",
        "dataset = SequenceDataset(sequences, max_seq_len, item_count)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 6. üîπ Mod√®le Transformer simple\n",
        "class TransformerRecModel(nn.Module):\n",
        "    def __init__(self, item_count, d_model=64, nhead=4, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(item_count, d_model, padding_idx=0)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output = nn.Linear(d_model, item_count)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # [batch_size, seq_len, d_model]\n",
        "        emb = emb.permute(1, 0, 2)  # [seq_len, batch_size, d_model]\n",
        "        out = self.transformer(emb)  # [seq_len, batch_size, d_model]\n",
        "        out = out[-1]  # dernier token: [batch_size, d_model]\n",
        "        return self.output(out)\n",
        "\n",
        "model = TransformerRecModel(item_count)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 7. üîπ Entra√Ænement\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for batch in loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x)\n",
        "        loss = loss_fn(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # üîπ Calcul pr√©cision\n",
        "        _, predicted = torch.max(preds, 1)\n",
        "        correct += (predicted == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"üìö Epoch {epoch+1} | Loss: {total_loss/len(loader):.4f} | Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# 8. üîπ Fonction de pr√©diction\n",
        "def recommend_next(session_items, model, item_encoder, max_len=10):\n",
        "    model.eval()\n",
        "    encoded = item_encoder.transform(session_items)\n",
        "    padded = [0] * (max_len - len(encoded)) + list(encoded[-max_len:])\n",
        "    X = torch.tensor([padded]).to(device)\n",
        "    with torch.no_grad():\n",
        "        scores = model(X)\n",
        "        top_item_id = torch.argmax(scores, dim=-1).item()\n",
        "        return item_encoder.inverse_transform([top_item_id])[0]\n",
        "\n",
        "# üîç Exemple de pr√©diction\n",
        "example_session = df[df[\"user_id\"] == df[\"user_id\"].iloc[0]][\"service_id\"].tolist()[:2]\n",
        "print(\"‚ñ∂Ô∏è Historique:\", example_session)\n",
        "predicted = recommend_next(example_session, model, item_encoder)\n",
        "print(\"üîÆ Item recommand√© :\", predicted)\n"
      ]
    }
  ]
}